# Connected papers

<img src="C:\Users\Winter\AppData\Roaming\Typora\typora-user-images\image-20230625173255361.png" alt="image-20230625173255361" style="zoom:50%;" />

## Derivative papers

<img src="C:\Users\Winter\AppData\Roaming\Typora\typora-user-images\image-20230625175142830.png" alt="image-20230625175142830" style="zoom:50%;" />

- [A Generative Adversarial Network Based Tone Mapping Operator for 4K HDR Images](https://www.semanticscholar.org/paper/3bf2fec99bbfa1c819cc96605a8649d3dd380b16)

  [github源码](https://github.com/zjbthomas/TMO-GAN)

  特点：
  
  - 数据集是成对的，由人工挑选得出。
  
  - working in the perceptual quantized domain
  
- [Unsupervised HDR Image and Video Tone Mapping via Contrastive Learning](https://www.semanticscholar.org/paper/7e1726888d102894d69a71ae583f39831d346020)

  [github源码](https://github.com/caocong/UnCLTMO)

  特点：video HDR

  

  

# Diffusion Model用于HDR

暂时未发现有将Diffusion Model用于HDR的研究。

一篇有趣的文献：https://arxiv.org/pdf/2108.01073.pdf

<img src="C:\Users\Winter\AppData\Roaming\Typora\typora-user-images\image-20230630212213877.png" alt="image-20230630212213877" style="zoom:67%;" />

**原理：**真实图像和我们画的图像分属两个分布，通过前向加噪过程让两个分布的支撑集越来越大，直到产生交集就停下。从交集中的一点出发，用在真实图像上训练好的扩散模型逆向去噪，就回到了真实分布。（加噪过程首先破坏的是高频信息，然后才破坏低频信息。所以当我们加噪到一定程度时，就可以去掉不想要的细节纹理，但仍保留大体结构，于是生成出来的图像就既能遵循输入的引导，又显得真实。）

**借鉴之处：**LDR图像和HDR图像的支撑集是否也能通过加噪实现扩大？





# 本论文的一些问题

- 分解器是判别谁和谁？
- 数据集配对？
